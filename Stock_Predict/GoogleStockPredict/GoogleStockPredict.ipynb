{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('GOOGL.csv')\n",
    "df = df.loc[:, ['Open', 'High', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.742737</td>\n",
       "      <td>243.358353</td>\n",
       "      <td>484.580017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243.838837</td>\n",
       "      <td>247.217224</td>\n",
       "      <td>493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245.970978</td>\n",
       "      <td>246.421417</td>\n",
       "      <td>487.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241.306305</td>\n",
       "      <td>241.671677</td>\n",
       "      <td>480.220032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.580582</td>\n",
       "      <td>240.615616</td>\n",
       "      <td>474.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237.237244</td>\n",
       "      <td>244.444443</td>\n",
       "      <td>482.800018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>242.252258</td>\n",
       "      <td>248.353348</td>\n",
       "      <td>493.649994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>248.518524</td>\n",
       "      <td>250.375381</td>\n",
       "      <td>497.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>251.246246</td>\n",
       "      <td>253.588593</td>\n",
       "      <td>506.380035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>253.623627</td>\n",
       "      <td>260.850861</td>\n",
       "      <td>521.030029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High       Close\n",
       "0  242.742737  243.358353  484.580017\n",
       "1  243.838837  247.217224  493.000000\n",
       "2  245.970978  246.421417  487.010010\n",
       "3  241.306305  241.671677  480.220032\n",
       "4  240.580582  240.615616  474.880005\n",
       "5  237.237244  244.444443  482.800018\n",
       "6  242.252258  248.353348  493.649994\n",
       "7  248.518524  250.375381  497.570007\n",
       "8  251.246246  253.588593  506.380035\n",
       "9  253.623627  260.850861  521.030029"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'GOOGL_use.csv'\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.427427</td>\n",
       "      <td>2.433584</td>\n",
       "      <td>4.8458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.438388</td>\n",
       "      <td>2.472172</td>\n",
       "      <td>4.9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.459710</td>\n",
       "      <td>2.464214</td>\n",
       "      <td>4.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.413063</td>\n",
       "      <td>2.416717</td>\n",
       "      <td>4.8022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.405806</td>\n",
       "      <td>2.406156</td>\n",
       "      <td>4.7488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High   Close\n",
       "0  2.427427  2.433584  4.8458\n",
       "1  2.438388  2.472172  4.9300\n",
       "2  2.459710  2.464214  4.8701\n",
       "3  2.413063  2.416717  4.8022\n",
       "4  2.405806  2.406156  4.7488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['High'] = df['High'] / 100\n",
    "df['Open'] = df['Open'] / 100\n",
    "df['Close'] = df['Close'] / 100\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() #pd.DataFrame(stock)\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1][:,-1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[2]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def build_model2(layers):\n",
    "        d = 0.2\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "        model.add(Dropout(d))\n",
    "        model.add(Dense(16,init='uniform',activation='relu'))        \n",
    "        model.add(Dense(1,init='uniform',activation='linear'))\n",
    "        model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (1338, 22, 3)\n",
      "y_train (1338,)\n",
      "X_test (149, 22, 3)\n",
      "y_test (149,)\n"
     ]
    }
   ],
   "source": [
    "window = 22\n",
    "X_train, y_train, X_test, y_test = load_data(df[::-1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>9.6965</td>\n",
       "      <td>9.7930</td>\n",
       "      <td>9.7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>9.5791</td>\n",
       "      <td>9.5995</td>\n",
       "      <td>9.5862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>9.4802</td>\n",
       "      <td>9.6068</td>\n",
       "      <td>9.6018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>9.7550</td>\n",
       "      <td>9.7970</td>\n",
       "      <td>9.6793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>9.7204</td>\n",
       "      <td>9.7791</td>\n",
       "      <td>9.7050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open    High   Close\n",
       "1509  9.6965  9.7930  9.7522\n",
       "1508  9.5791  9.5995  9.5862\n",
       "1507  9.4802  9.6068  9.6018\n",
       "1506  9.7550  9.7970  9.6793\n",
       "1505  9.7204  9.7791  9.7050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[::-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "c:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"linear\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "model = build_model2([3,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py:851: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1204 samples, validate on 134 samples\n",
      "Epoch 1/500\n",
      "1204/1204 [==============================] - 3s - loss: 58.8912 - acc: 0.0000e+00 - val_loss: 36.0690 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1204/1204 [==============================] - 2s - loss: 58.3111 - acc: 0.0000e+00 - val_loss: 35.5575 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1204/1204 [==============================] - 2s - loss: 57.6093 - acc: 0.0000e+00 - val_loss: 34.8622 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1204/1204 [==============================] - 2s - loss: 56.7019 - acc: 0.0000e+00 - val_loss: 33.9660 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1204/1204 [==============================] - 2s - loss: 55.5182 - acc: 0.0000e+00 - val_loss: 32.7869 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1204/1204 [==============================] - 2s - loss: 53.9349 - acc: 0.0000e+00 - val_loss: 31.2115 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1204/1204 [==============================] - 2s - loss: 51.8915 - acc: 0.0000e+00 - val_loss: 29.3127 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1204/1204 [==============================] - 2s - loss: 49.4641 - acc: 0.0000e+00 - val_loss: 27.3064 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1204/1204 [==============================] - 2s - loss: 46.9003 - acc: 0.0000e+00 - val_loss: 25.2627 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1204/1204 [==============================] - 2s - loss: 44.2393 - acc: 0.0000e+00 - val_loss: 23.2176 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1204/1204 [==============================] - 2s - loss: 41.5744 - acc: 0.0000e+00 - val_loss: 21.0774 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1204/1204 [==============================] - 2s - loss: 38.7046 - acc: 0.0000e+00 - val_loss: 18.8478 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1204/1204 [==============================] - 2s - loss: 35.6695 - acc: 0.0000e+00 - val_loss: 16.5649 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1204/1204 [==============================] - 2s - loss: 32.6039 - acc: 0.0000e+00 - val_loss: 14.2556 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1204/1204 [==============================] - 2s - loss: 29.3404 - acc: 0.0000e+00 - val_loss: 11.9734 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1204/1204 [==============================] - 2s - loss: 26.2400 - acc: 0.0000e+00 - val_loss: 9.7908 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1204/1204 [==============================] - 2s - loss: 23.0268 - acc: 0.0000e+00 - val_loss: 7.7352 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1204/1204 [==============================] - 2s - loss: 20.0790 - acc: 0.0000e+00 - val_loss: 5.8429 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1204/1204 [==============================] - 2s - loss: 17.1431 - acc: 0.0000e+00 - val_loss: 4.1813 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1204/1204 [==============================] - 2s - loss: 14.3502 - acc: 0.0000e+00 - val_loss: 2.7758 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1204/1204 [==============================] - 1s - loss: 12.0278 - acc: 0.0000e+00 - val_loss: 1.6518 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1204/1204 [==============================] - 2s - loss: 9.8299 - acc: 0.0000e+00 - val_loss: 0.8289 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1204/1204 [==============================] - 1s - loss: 7.9517 - acc: 0.0000e+00 - val_loss: 0.3067 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1204/1204 [==============================] - 2s - loss: 6.5027 - acc: 0.0000e+00 - val_loss: 0.0736 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1204/1204 [==============================] - 2s - loss: 5.2205 - acc: 0.0000e+00 - val_loss: 0.0983 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1204/1204 [==============================] - 2s - loss: 4.2849 - acc: 0.0000e+00 - val_loss: 0.3309 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.6576 - acc: 0.0000e+00 - val_loss: 0.7110 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.2161 - acc: 0.0000e+00 - val_loss: 1.1737 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.1033 - acc: 0.0000e+00 - val_loss: 1.6582 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0053 - acc: 0.0000e+00 - val_loss: 2.1124 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0645 - acc: 0.0000e+00 - val_loss: 2.4896 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9647 - acc: 0.0000e+00 - val_loss: 2.7659 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0946 - acc: 0.0000e+00 - val_loss: 2.9340 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0868 - acc: 0.0000e+00 - val_loss: 3.0041 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0218 - acc: 0.0000e+00 - val_loss: 2.9982 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0042 - acc: 0.0000e+00 - val_loss: 2.9258 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9346 - acc: 0.0000e+00 - val_loss: 2.8142 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9682 - acc: 0.0000e+00 - val_loss: 2.6958 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0039 - acc: 0.0000e+00 - val_loss: 2.5820 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0292 - acc: 0.0000e+00 - val_loss: 2.4578 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0241 - acc: 0.0000e+00 - val_loss: 2.3482 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0241 - acc: 0.0000e+00 - val_loss: 2.2486 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0396 - acc: 0.0000e+00 - val_loss: 2.1577 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9007 - acc: 0.0000e+00 - val_loss: 2.0844 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9908 - acc: 0.0000e+00 - val_loss: 2.0270 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9054 - acc: 0.0000e+00 - val_loss: 1.9908 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9243 - acc: 0.0000e+00 - val_loss: 1.9790 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9302 - acc: 0.0000e+00 - val_loss: 1.9862 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9016 - acc: 0.0000e+00 - val_loss: 2.0053 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9874 - acc: 0.0000e+00 - val_loss: 2.0272 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0090 - acc: 0.0000e+00 - val_loss: 2.0536 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9811 - acc: 0.0000e+00 - val_loss: 2.0700 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8271 - acc: 0.0000e+00 - val_loss: 2.0841 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9952 - acc: 0.0000e+00 - val_loss: 2.1022 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9315 - acc: 0.0000e+00 - val_loss: 2.1091 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9692 - acc: 0.0000e+00 - val_loss: 2.1115 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9390 - acc: 0.0000e+00 - val_loss: 2.1142 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0149 - acc: 0.0000e+00 - val_loss: 2.1240 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0052 - acc: 0.0000e+00 - val_loss: 2.1250 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9697 - acc: 0.0000e+00 - val_loss: 2.1395 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9307 - acc: 0.0000e+00 - val_loss: 2.1539 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0149 - acc: 0.0000e+00 - val_loss: 2.1693 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8809 - acc: 0.0000e+00 - val_loss: 2.1810 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0454 - acc: 0.0000e+00 - val_loss: 2.1798 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9408 - acc: 0.0000e+00 - val_loss: 2.1871 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0001 - acc: 0.0000e+00 - val_loss: 2.1786 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9279 - acc: 0.0000e+00 - val_loss: 2.1769 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9890 - acc: 0.0000e+00 - val_loss: 2.1669 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9508 - acc: 0.0000e+00 - val_loss: 2.1573 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0263 - acc: 0.0000e+00 - val_loss: 2.1544 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9167 - acc: 0.0000e+00 - val_loss: 2.1504 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9378 - acc: 0.0000e+00 - val_loss: 2.1432 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9597 - acc: 0.0000e+00 - val_loss: 2.1378 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0134 - acc: 0.0000e+00 - val_loss: 2.1299 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9772 - acc: 0.0000e+00 - val_loss: 2.1093 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9518 - acc: 0.0000e+00 - val_loss: 2.1022 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8717 - acc: 0.0000e+00 - val_loss: 2.1113 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9358 - acc: 0.0000e+00 - val_loss: 2.1295 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9722 - acc: 0.0000e+00 - val_loss: 2.1431 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0666 - acc: 0.0000e+00 - val_loss: 2.1596 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9658 - acc: 0.0000e+00 - val_loss: 2.1472 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9476 - acc: 0.0000e+00 - val_loss: 2.1305 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9428 - acc: 0.0000e+00 - val_loss: 2.1303 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9919 - acc: 0.0000e+00 - val_loss: 2.1235 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9423 - acc: 0.0000e+00 - val_loss: 2.1167 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9357 - acc: 0.0000e+00 - val_loss: 2.1066 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9573 - acc: 0.0000e+00 - val_loss: 2.0923 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9264 - acc: 0.0000e+00 - val_loss: 2.0749 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0475 - acc: 0.0000e+00 - val_loss: 2.0825 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9090 - acc: 0.0000e+00 - val_loss: 2.0877 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0010 - acc: 0.0000e+00 - val_loss: 2.1087 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9585 - acc: 0.0000e+00 - val_loss: 2.1260 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9456 - acc: 0.0000e+00 - val_loss: 2.1275 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9215 - acc: 0.0000e+00 - val_loss: 2.1393 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9447 - acc: 0.0000e+00 - val_loss: 2.1481 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9088 - acc: 0.0000e+00 - val_loss: 2.1636 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9373 - acc: 0.0000e+00 - val_loss: 2.1773 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9739 - acc: 0.0000e+00 - val_loss: 2.1950 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9492 - acc: 0.0000e+00 - val_loss: 2.1980 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9288 - acc: 0.0000e+00 - val_loss: 2.1777 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9553 - acc: 0.0000e+00 - val_loss: 2.1525 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9264 - acc: 0.0000e+00 - val_loss: 2.1150 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0325 - acc: 0.0000e+00 - val_loss: 2.0839 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9755 - acc: 0.0000e+00 - val_loss: 2.0710 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0017 - acc: 0.0000e+00 - val_loss: 2.0508 - val_acc: 0.0000e+00\n",
      "Epoch 106/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9003 - acc: 0.0000e+00 - val_loss: 2.0425 - val_acc: 0.0000e+00\n",
      "Epoch 107/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9629 - acc: 0.0000e+00 - val_loss: 2.0524 - val_acc: 0.0000e+00\n",
      "Epoch 108/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8580 - acc: 0.0000e+00 - val_loss: 2.0816 - val_acc: 0.0000e+00\n",
      "Epoch 109/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9455 - acc: 0.0000e+00 - val_loss: 2.1147 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0213 - acc: 0.0000e+00 - val_loss: 2.1425 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9269 - acc: 0.0000e+00 - val_loss: 2.1554 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0236 - acc: 0.0000e+00 - val_loss: 2.1514 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9065 - acc: 0.0000e+00 - val_loss: 2.1440 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9840 - acc: 0.0000e+00 - val_loss: 2.1315 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9139 - acc: 0.0000e+00 - val_loss: 2.1395 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9919 - acc: 0.0000e+00 - val_loss: 2.1355 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9084 - acc: 0.0000e+00 - val_loss: 2.1435 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0024 - acc: 0.0000e+00 - val_loss: 2.1585 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9083 - acc: 0.0000e+00 - val_loss: 2.1593 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9841 - acc: 0.0000e+00 - val_loss: 2.1560 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9036 - acc: 0.0000e+00 - val_loss: 2.1604 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9522 - acc: 0.0000e+00 - val_loss: 2.1513 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9720 - acc: 0.0000e+00 - val_loss: 2.1430 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9637 - acc: 0.0000e+00 - val_loss: 2.1281 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9158 - acc: 0.0000e+00 - val_loss: 2.1257 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0078 - acc: 0.0000e+00 - val_loss: 2.1335 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9428 - acc: 0.0000e+00 - val_loss: 2.1280 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9136 - acc: 0.0000e+00 - val_loss: 2.1248 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9436 - acc: 0.0000e+00 - val_loss: 2.1248 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8801 - acc: 0.0000e+00 - val_loss: 2.1330 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9335 - acc: 0.0000e+00 - val_loss: 2.1329 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9958 - acc: 0.0000e+00 - val_loss: 2.1234 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9415 - acc: 0.0000e+00 - val_loss: 2.1225 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0147 - acc: 0.0000e+00 - val_loss: 2.1194 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9222 - acc: 0.0000e+00 - val_loss: 2.1188 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9350 - acc: 0.0000e+00 - val_loss: 2.1186 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9155 - acc: 0.0000e+00 - val_loss: 2.1110 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9344 - acc: 0.0000e+00 - val_loss: 2.1009 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "1204/1204 [==============================] - 3s - loss: 2.9533 - acc: 0.0000e+00 - val_loss: 2.1080 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9559 - acc: 0.0000e+00 - val_loss: 2.1225 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9639 - acc: 0.0000e+00 - val_loss: 2.1377 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9514 - acc: 0.0000e+00 - val_loss: 2.1544 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9818 - acc: 0.0000e+00 - val_loss: 2.1599 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9979 - acc: 0.0000e+00 - val_loss: 2.1537 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0041 - acc: 0.0000e+00 - val_loss: 2.1446 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9144 - acc: 0.0000e+00 - val_loss: 2.1346 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9225 - acc: 0.0000e+00 - val_loss: 2.1101 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9362 - acc: 0.0000e+00 - val_loss: 2.0940 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9679 - acc: 0.0000e+00 - val_loss: 2.0896 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9553 - acc: 0.0000e+00 - val_loss: 2.0882 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9494 - acc: 0.0000e+00 - val_loss: 2.0882 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0014 - acc: 0.0000e+00 - val_loss: 2.0995 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9090 - acc: 0.0000e+00 - val_loss: 2.1139 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9509 - acc: 0.0000e+00 - val_loss: 2.1226 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9885 - acc: 0.0000e+00 - val_loss: 2.1384 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9805 - acc: 0.0000e+00 - val_loss: 2.1435 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9862 - acc: 0.0000e+00 - val_loss: 2.1541 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0426 - acc: 0.0000e+00 - val_loss: 2.1425 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9163 - acc: 0.0000e+00 - val_loss: 2.1340 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9852 - acc: 0.0000e+00 - val_loss: 2.1202 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9580 - acc: 0.0000e+00 - val_loss: 2.0972 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9971 - acc: 0.0000e+00 - val_loss: 2.1143 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9836 - acc: 0.0000e+00 - val_loss: 2.1390 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0608 - acc: 0.0000e+00 - val_loss: 2.1569 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9600 - acc: 0.0000e+00 - val_loss: 2.1768 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9327 - acc: 0.0000e+00 - val_loss: 2.1765 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9778 - acc: 0.0000e+00 - val_loss: 2.1725 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9433 - acc: 0.0000e+00 - val_loss: 2.1684 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9742 - acc: 0.0000e+00 - val_loss: 2.1663 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9971 - acc: 0.0000e+00 - val_loss: 2.1611 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9533 - acc: 0.0000e+00 - val_loss: 2.1438 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0740 - acc: 0.0000e+00 - val_loss: 2.1209 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0023 - acc: 0.0000e+00 - val_loss: 2.0936 - val_acc: 0.0000e+00\n",
      "Epoch 174/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8565 - acc: 0.0000e+00 - val_loss: 2.0859 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8941 - acc: 0.0000e+00 - val_loss: 2.0833 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8574 - acc: 0.0000e+00 - val_loss: 2.0943 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9692 - acc: 0.0000e+00 - val_loss: 2.1121 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9947 - acc: 0.0000e+00 - val_loss: 2.1526 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0162 - acc: 0.0000e+00 - val_loss: 2.1590 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9441 - acc: 0.0000e+00 - val_loss: 2.1573 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9573 - acc: 0.0000e+00 - val_loss: 2.1410 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9118 - acc: 0.0000e+00 - val_loss: 2.1308 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0300 - acc: 0.0000e+00 - val_loss: 2.1207 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0287 - acc: 0.0000e+00 - val_loss: 2.0982 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9178 - acc: 0.0000e+00 - val_loss: 2.0936 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9451 - acc: 0.0000e+00 - val_loss: 2.0952 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9200 - acc: 0.0000e+00 - val_loss: 2.1164 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0159 - acc: 0.0000e+00 - val_loss: 2.1323 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9974 - acc: 0.0000e+00 - val_loss: 2.1336 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0519 - acc: 0.0000e+00 - val_loss: 2.1401 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9982 - acc: 0.0000e+00 - val_loss: 2.1391 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0073 - acc: 0.0000e+00 - val_loss: 2.1381 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9669 - acc: 0.0000e+00 - val_loss: 2.1267 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0158 - acc: 0.0000e+00 - val_loss: 2.1038 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9634 - acc: 0.0000e+00 - val_loss: 2.0873 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9775 - acc: 0.0000e+00 - val_loss: 2.0746 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9501 - acc: 0.0000e+00 - val_loss: 2.0658 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9456 - acc: 0.0000e+00 - val_loss: 2.0644 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9934 - acc: 0.0000e+00 - val_loss: 2.0877 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9442 - acc: 0.0000e+00 - val_loss: 2.0928 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9453 - acc: 0.0000e+00 - val_loss: 2.0993 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8965 - acc: 0.0000e+00 - val_loss: 2.1074 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0055 - acc: 0.0000e+00 - val_loss: 2.1130 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9342 - acc: 0.0000e+00 - val_loss: 2.1081 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0284 - acc: 0.0000e+00 - val_loss: 2.0923 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9374 - acc: 0.0000e+00 - val_loss: 2.0996 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8987 - acc: 0.0000e+00 - val_loss: 2.1229 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9175 - acc: 0.0000e+00 - val_loss: 2.1489 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9994 - acc: 0.0000e+00 - val_loss: 2.1725 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9698 - acc: 0.0000e+00 - val_loss: 2.1743 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0018 - acc: 0.0000e+00 - val_loss: 2.1692 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9518 - acc: 0.0000e+00 - val_loss: 2.1649 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9636 - acc: 0.0000e+00 - val_loss: 2.1460 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9642 - acc: 0.0000e+00 - val_loss: 2.1408 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0073 - acc: 0.0000e+00 - val_loss: 2.1309 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9457 - acc: 0.0000e+00 - val_loss: 2.1348 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9637 - acc: 0.0000e+00 - val_loss: 2.1305 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0242 - acc: 0.0000e+00 - val_loss: 2.1258 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9609 - acc: 0.0000e+00 - val_loss: 2.1395 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.8990 - acc: 0.0000e+00 - val_loss: 2.1468 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0290 - acc: 0.0000e+00 - val_loss: 2.1651 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9279 - acc: 0.0000e+00 - val_loss: 2.1957 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0172 - acc: 0.0000e+00 - val_loss: 2.2008 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0086 - acc: 0.0000e+00 - val_loss: 2.1972 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9382 - acc: 0.0000e+00 - val_loss: 2.1856 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9465 - acc: 0.0000e+00 - val_loss: 2.1425 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9895 - acc: 0.0000e+00 - val_loss: 2.1145 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9233 - acc: 0.0000e+00 - val_loss: 2.0894 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9938 - acc: 0.0000e+00 - val_loss: 2.0868 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9707 - acc: 0.0000e+00 - val_loss: 2.0842 - val_acc: 0.0000e+00\n",
      "Epoch 231/500\n",
      "1204/1204 [==============================] - 3s - loss: 2.9383 - acc: 0.0000e+00 - val_loss: 2.0798 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9611 - acc: 0.0000e+00 - val_loss: 2.0710 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9787 - acc: 0.0000e+00 - val_loss: 2.0874 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9349 - acc: 0.0000e+00 - val_loss: 2.1022 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9929 - acc: 0.0000e+00 - val_loss: 2.1361 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9632 - acc: 0.0000e+00 - val_loss: 2.1827 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9602 - acc: 0.0000e+00 - val_loss: 2.2109 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9482 - acc: 0.0000e+00 - val_loss: 2.2016 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9489 - acc: 0.0000e+00 - val_loss: 2.1945 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9988 - acc: 0.0000e+00 - val_loss: 2.1951 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9406 - acc: 0.0000e+00 - val_loss: 2.1784 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9266 - acc: 0.0000e+00 - val_loss: 2.1713 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0202 - acc: 0.0000e+00 - val_loss: 2.1565 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8968 - acc: 0.0000e+00 - val_loss: 2.1538 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0325 - acc: 0.0000e+00 - val_loss: 2.1260 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9141 - acc: 0.0000e+00 - val_loss: 2.0891 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0459 - acc: 0.0000e+00 - val_loss: 2.0483 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9779 - acc: 0.0000e+00 - val_loss: 2.0147 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9356 - acc: 0.0000e+00 - val_loss: 2.0187 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9914 - acc: 0.0000e+00 - val_loss: 2.0382 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0615 - acc: 0.0000e+00 - val_loss: 2.0595 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0210 - acc: 0.0000e+00 - val_loss: 2.0908 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0401 - acc: 0.0000e+00 - val_loss: 2.1215 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9458 - acc: 0.0000e+00 - val_loss: 2.1027 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9218 - acc: 0.0000e+00 - val_loss: 2.0751 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9030 - acc: 0.0000e+00 - val_loss: 2.0532 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9258 - acc: 0.0000e+00 - val_loss: 2.0607 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8780 - acc: 0.0000e+00 - val_loss: 2.0706 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9956 - acc: 0.0000e+00 - val_loss: 2.0955 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9828 - acc: 0.0000e+00 - val_loss: 2.1096 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9682 - acc: 0.0000e+00 - val_loss: 2.1331 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9208 - acc: 0.0000e+00 - val_loss: 2.1668 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8508 - acc: 0.0000e+00 - val_loss: 2.2003 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8918 - acc: 0.0000e+00 - val_loss: 2.2195 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9787 - acc: 0.0000e+00 - val_loss: 2.2103 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9947 - acc: 0.0000e+00 - val_loss: 2.1871 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0417 - acc: 0.0000e+00 - val_loss: 2.1596 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9916 - acc: 0.0000e+00 - val_loss: 2.1374 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9240 - acc: 0.0000e+00 - val_loss: 2.1163 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "1204/1204 [==============================] - 1s - loss: 3.0563 - acc: 0.0000e+00 - val_loss: 2.0993 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.8454 - acc: 0.0000e+00 - val_loss: 2.0533 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9820 - acc: 0.0000e+00 - val_loss: 2.0215 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9448 - acc: 0.0000e+00 - val_loss: 2.0077 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9506 - acc: 0.0000e+00 - val_loss: 2.0161 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9811 - acc: 0.0000e+00 - val_loss: 2.0443 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0103 - acc: 0.0000e+00 - val_loss: 2.0600 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9563 - acc: 0.0000e+00 - val_loss: 2.0805 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9368 - acc: 0.0000e+00 - val_loss: 2.1244 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0357 - acc: 0.0000e+00 - val_loss: 2.1634 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9967 - acc: 0.0000e+00 - val_loss: 2.1742 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9610 - acc: 0.0000e+00 - val_loss: 2.1644 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9968 - acc: 0.0000e+00 - val_loss: 2.1430 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0599 - acc: 0.0000e+00 - val_loss: 2.1182 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9552 - acc: 0.0000e+00 - val_loss: 2.0997 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9673 - acc: 0.0000e+00 - val_loss: 2.0877 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9334 - acc: 0.0000e+00 - val_loss: 2.0802 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9896 - acc: 0.0000e+00 - val_loss: 2.0960 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9095 - acc: 0.0000e+00 - val_loss: 2.0970 - val_acc: 0.0000e+00\n",
      "Epoch 289/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9938 - acc: 0.0000e+00 - val_loss: 2.0793 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8602 - acc: 0.0000e+00 - val_loss: 2.0643 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9329 - acc: 0.0000e+00 - val_loss: 2.0598 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9975 - acc: 0.0000e+00 - val_loss: 2.0783 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9664 - acc: 0.0000e+00 - val_loss: 2.0996 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.1256 - acc: 0.0000e+00 - val_loss: 2.1007 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9937 - acc: 0.0000e+00 - val_loss: 2.1076 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9543 - acc: 0.0000e+00 - val_loss: 2.1110 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0178 - acc: 0.0000e+00 - val_loss: 2.1070 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9193 - acc: 0.0000e+00 - val_loss: 2.1125 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9024 - acc: 0.0000e+00 - val_loss: 2.1091 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9468 - acc: 0.0000e+00 - val_loss: 2.0949 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9555 - acc: 0.0000e+00 - val_loss: 2.0965 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9414 - acc: 0.0000e+00 - val_loss: 2.1125 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9791 - acc: 0.0000e+00 - val_loss: 2.1519 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9451 - acc: 0.0000e+00 - val_loss: 2.2091 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9638 - acc: 0.0000e+00 - val_loss: 2.2340 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9399 - acc: 0.0000e+00 - val_loss: 2.2083 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0023 - acc: 0.0000e+00 - val_loss: 2.1820 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9989 - acc: 0.0000e+00 - val_loss: 2.1635 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9876 - acc: 0.0000e+00 - val_loss: 2.1521 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0206 - acc: 0.0000e+00 - val_loss: 2.1429 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9425 - acc: 0.0000e+00 - val_loss: 2.1231 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9106 - acc: 0.0000e+00 - val_loss: 2.1386 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9952 - acc: 0.0000e+00 - val_loss: 2.1148 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9706 - acc: 0.0000e+00 - val_loss: 2.0940 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9977 - acc: 0.0000e+00 - val_loss: 2.0862 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8675 - acc: 0.0000e+00 - val_loss: 2.1133 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9521 - acc: 0.0000e+00 - val_loss: 2.1503 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9083 - acc: 0.0000e+00 - val_loss: 2.1570 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0024 - acc: 0.0000e+00 - val_loss: 2.1637 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9142 - acc: 0.0000e+00 - val_loss: 2.1756 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9270 - acc: 0.0000e+00 - val_loss: 2.1931 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9810 - acc: 0.0000e+00 - val_loss: 2.2057 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9681 - acc: 0.0000e+00 - val_loss: 2.2245 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9763 - acc: 0.0000e+00 - val_loss: 2.2142 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9509 - acc: 0.0000e+00 - val_loss: 2.1679 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0005 - acc: 0.0000e+00 - val_loss: 2.1098 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9829 - acc: 0.0000e+00 - val_loss: 2.0704 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9896 - acc: 0.0000e+00 - val_loss: 2.0314 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9944 - acc: 0.0000e+00 - val_loss: 1.9949 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9293 - acc: 0.0000e+00 - val_loss: 1.9952 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9594 - acc: 0.0000e+00 - val_loss: 2.0118 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9689 - acc: 0.0000e+00 - val_loss: 2.0607 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9351 - acc: 0.0000e+00 - val_loss: 2.1247 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9876 - acc: 0.0000e+00 - val_loss: 2.1256 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9941 - acc: 0.0000e+00 - val_loss: 2.1360 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9919 - acc: 0.0000e+00 - val_loss: 2.1360 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8995 - acc: 0.0000e+00 - val_loss: 2.1536 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0332 - acc: 0.0000e+00 - val_loss: 2.1622 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9664 - acc: 0.0000e+00 - val_loss: 2.1793 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9576 - acc: 0.0000e+00 - val_loss: 2.1728 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9757 - acc: 0.0000e+00 - val_loss: 2.1386 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9677 - acc: 0.0000e+00 - val_loss: 2.1075 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0147 - acc: 0.0000e+00 - val_loss: 2.1099 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0287 - acc: 0.0000e+00 - val_loss: 2.1241 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8878 - acc: 0.0000e+00 - val_loss: 2.1175 - val_acc: 0.0000e+00\n",
      "Epoch 346/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9867 - acc: 0.0000e+00 - val_loss: 2.1254 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9118 - acc: 0.0000e+00 - val_loss: 2.1257 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9684 - acc: 0.0000e+00 - val_loss: 2.1312 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9532 - acc: 0.0000e+00 - val_loss: 2.1501 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9828 - acc: 0.0000e+00 - val_loss: 2.1656 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9448 - acc: 0.0000e+00 - val_loss: 2.1614 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9617 - acc: 0.0000e+00 - val_loss: 2.1693 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9327 - acc: 0.0000e+00 - val_loss: 2.1915 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9962 - acc: 0.0000e+00 - val_loss: 2.1671 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8457 - acc: 0.0000e+00 - val_loss: 2.1541 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9865 - acc: 0.0000e+00 - val_loss: 2.0977 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9584 - acc: 0.0000e+00 - val_loss: 2.0435 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9265 - acc: 0.0000e+00 - val_loss: 2.0419 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0164 - acc: 0.0000e+00 - val_loss: 2.0653 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9046 - acc: 0.0000e+00 - val_loss: 2.1084 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 3.0366 - acc: 0.0000e+00 - val_loss: 2.1518 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9428 - acc: 0.0000e+00 - val_loss: 2.1626 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9639 - acc: 0.0000e+00 - val_loss: 2.1462 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9126 - acc: 0.0000e+00 - val_loss: 2.1395 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9670 - acc: 0.0000e+00 - val_loss: 2.1641 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0246 - acc: 0.0000e+00 - val_loss: 2.1751 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9058 - acc: 0.0000e+00 - val_loss: 2.1673 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9708 - acc: 0.0000e+00 - val_loss: 2.1248 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8952 - acc: 0.0000e+00 - val_loss: 2.0973 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9471 - acc: 0.0000e+00 - val_loss: 2.0593 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0198 - acc: 0.0000e+00 - val_loss: 2.0748 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9921 - acc: 0.0000e+00 - val_loss: 2.0726 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0690 - acc: 0.0000e+00 - val_loss: 2.0572 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9131 - acc: 0.0000e+00 - val_loss: 2.0704 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8808 - acc: 0.0000e+00 - val_loss: 2.1099 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8977 - acc: 0.0000e+00 - val_loss: 2.1853 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9778 - acc: 0.0000e+00 - val_loss: 2.2654 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8922 - acc: 0.0000e+00 - val_loss: 2.3028 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9238 - acc: 0.0000e+00 - val_loss: 2.2633 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9843 - acc: 0.0000e+00 - val_loss: 2.1910 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0288 - acc: 0.0000e+00 - val_loss: 2.1447 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9080 - acc: 0.0000e+00 - val_loss: 2.0791 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9789 - acc: 0.0000e+00 - val_loss: 2.0317 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8842 - acc: 0.0000e+00 - val_loss: 1.9987 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8403 - acc: 0.0000e+00 - val_loss: 2.0240 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8891 - acc: 0.0000e+00 - val_loss: 2.0941 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9542 - acc: 0.0000e+00 - val_loss: 2.1736 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9710 - acc: 0.0000e+00 - val_loss: 2.2086 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9730 - acc: 0.0000e+00 - val_loss: 2.2033 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9892 - acc: 0.0000e+00 - val_loss: 2.2027 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9773 - acc: 0.0000e+00 - val_loss: 2.2324 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9362 - acc: 0.0000e+00 - val_loss: 2.2152 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0140 - acc: 0.0000e+00 - val_loss: 2.1556 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9386 - acc: 0.0000e+00 - val_loss: 2.1120 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9680 - acc: 0.0000e+00 - val_loss: 2.0701 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9654 - acc: 0.0000e+00 - val_loss: 2.0476 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0131 - acc: 0.0000e+00 - val_loss: 2.0839 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8817 - acc: 0.0000e+00 - val_loss: 2.1115 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9502 - acc: 0.0000e+00 - val_loss: 2.1163 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9513 - acc: 0.0000e+00 - val_loss: 2.1285 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9785 - acc: 0.0000e+00 - val_loss: 2.1116 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8979 - acc: 0.0000e+00 - val_loss: 2.0950 - val_acc: 0.0000e+00\n",
      "Epoch 403/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9491 - acc: 0.0000e+00 - val_loss: 2.0978 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9255 - acc: 0.0000e+00 - val_loss: 2.1248 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0044 - acc: 0.0000e+00 - val_loss: 2.1674 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9905 - acc: 0.0000e+00 - val_loss: 2.1693 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9360 - acc: 0.0000e+00 - val_loss: 2.1587 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9421 - acc: 0.0000e+00 - val_loss: 2.1121 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9273 - acc: 0.0000e+00 - val_loss: 2.0854 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9644 - acc: 0.0000e+00 - val_loss: 2.0766 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9698 - acc: 0.0000e+00 - val_loss: 2.0918 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9988 - acc: 0.0000e+00 - val_loss: 2.0638 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0635 - acc: 0.0000e+00 - val_loss: 2.0747 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9426 - acc: 0.0000e+00 - val_loss: 2.1173 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9613 - acc: 0.0000e+00 - val_loss: 2.1580 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0591 - acc: 0.0000e+00 - val_loss: 2.1547 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0756 - acc: 0.0000e+00 - val_loss: 2.1465 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9697 - acc: 0.0000e+00 - val_loss: 2.1179 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9538 - acc: 0.0000e+00 - val_loss: 2.0869 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9660 - acc: 0.0000e+00 - val_loss: 2.0975 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 3.0014 - acc: 0.0000e+00 - val_loss: 2.1258 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9291 - acc: 0.0000e+00 - val_loss: 2.1328 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9857 - acc: 0.0000e+00 - val_loss: 2.1457 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9537 - acc: 0.0000e+00 - val_loss: 2.1792 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9229 - acc: 0.0000e+00 - val_loss: 2.2027 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "1204/1204 [==============================] - 1s - loss: 2.9097 - acc: 0.0000e+00 - val_loss: 2.1389 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0386 - acc: 0.0000e+00 - val_loss: 2.0624 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9835 - acc: 0.0000e+00 - val_loss: 2.0174 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0146 - acc: 0.0000e+00 - val_loss: 2.0357 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9485 - acc: 0.0000e+00 - val_loss: 2.0524 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9254 - acc: 0.0000e+00 - val_loss: 2.0871 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9524 - acc: 0.0000e+00 - val_loss: 2.1302 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9711 - acc: 0.0000e+00 - val_loss: 2.1792 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9592 - acc: 0.0000e+00 - val_loss: 2.2503 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9652 - acc: 0.0000e+00 - val_loss: 2.2758 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0272 - acc: 0.0000e+00 - val_loss: 2.2330 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9719 - acc: 0.0000e+00 - val_loss: 2.1560 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9543 - acc: 0.0000e+00 - val_loss: 2.0689 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9739 - acc: 0.0000e+00 - val_loss: 2.0310 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9977 - acc: 0.0000e+00 - val_loss: 2.0348 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9448 - acc: 0.0000e+00 - val_loss: 2.0460 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9689 - acc: 0.0000e+00 - val_loss: 2.0706 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0356 - acc: 0.0000e+00 - val_loss: 2.1186 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8830 - acc: 0.0000e+00 - val_loss: 2.1780 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9325 - acc: 0.0000e+00 - val_loss: 2.2253 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0130 - acc: 0.0000e+00 - val_loss: 2.2537 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9186 - acc: 0.0000e+00 - val_loss: 2.2915 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9483 - acc: 0.0000e+00 - val_loss: 2.2518 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9188 - acc: 0.0000e+00 - val_loss: 2.1676 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9673 - acc: 0.0000e+00 - val_loss: 2.0619 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9699 - acc: 0.0000e+00 - val_loss: 2.0101 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0425 - acc: 0.0000e+00 - val_loss: 2.0029 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9618 - acc: 0.0000e+00 - val_loss: 2.0212 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9772 - acc: 0.0000e+00 - val_loss: 2.0769 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9644 - acc: 0.0000e+00 - val_loss: 2.1140 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9174 - acc: 0.0000e+00 - val_loss: 2.1437 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0135 - acc: 0.0000e+00 - val_loss: 2.1322 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9313 - acc: 0.0000e+00 - val_loss: 2.1001 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9193 - acc: 0.0000e+00 - val_loss: 2.0908 - val_acc: 0.0000e+00\n",
      "Epoch 460/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8612 - acc: 0.0000e+00 - val_loss: 2.0930 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9407 - acc: 0.0000e+00 - val_loss: 2.1106 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9387 - acc: 0.0000e+00 - val_loss: 2.1467 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0436 - acc: 0.0000e+00 - val_loss: 2.1887 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0249 - acc: 0.0000e+00 - val_loss: 2.1821 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8958 - acc: 0.0000e+00 - val_loss: 2.1456 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9726 - acc: 0.0000e+00 - val_loss: 2.0966 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9551 - acc: 0.0000e+00 - val_loss: 2.0404 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9780 - acc: 0.0000e+00 - val_loss: 2.0891 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9339 - acc: 0.0000e+00 - val_loss: 2.1371 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8653 - acc: 0.0000e+00 - val_loss: 2.1572 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0458 - acc: 0.0000e+00 - val_loss: 2.1693 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9724 - acc: 0.0000e+00 - val_loss: 2.1396 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9258 - acc: 0.0000e+00 - val_loss: 2.0869 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9726 - acc: 0.0000e+00 - val_loss: 2.0923 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9942 - acc: 0.0000e+00 - val_loss: 2.0914 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9448 - acc: 0.0000e+00 - val_loss: 2.0971 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9234 - acc: 0.0000e+00 - val_loss: 2.1153 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9314 - acc: 0.0000e+00 - val_loss: 2.1125 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9857 - acc: 0.0000e+00 - val_loss: 2.1656 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9782 - acc: 0.0000e+00 - val_loss: 2.1778 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s - loss: 2.9822 - acc: 0.0000e+00 - val_loss: 2.1912 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9038 - acc: 0.0000e+00 - val_loss: 2.1798 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9665 - acc: 0.0000e+00 - val_loss: 2.1484 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9183 - acc: 0.0000e+00 - val_loss: 2.1305 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9477 - acc: 0.0000e+00 - val_loss: 2.1430 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0110 - acc: 0.0000e+00 - val_loss: 2.1545 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9600 - acc: 0.0000e+00 - val_loss: 2.1916 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9701 - acc: 0.0000e+00 - val_loss: 2.1965 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9375 - acc: 0.0000e+00 - val_loss: 2.2063 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9622 - acc: 0.0000e+00 - val_loss: 2.1954 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9748 - acc: 0.0000e+00 - val_loss: 2.1969 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8975 - acc: 0.0000e+00 - val_loss: 2.2168 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.8779 - acc: 0.0000e+00 - val_loss: 2.2268 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "1204/1204 [==============================] - 2s - loss: 3.0373 - acc: 0.0000e+00 - val_loss: 2.2119 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9478 - acc: 0.0000e+00 - val_loss: 2.1420 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9288 - acc: 0.0000e+00 - val_loss: 2.1056 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9158 - acc: 0.0000e+00 - val_loss: 2.1230 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9503 - acc: 0.0000e+00 - val_loss: 2.1583 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9820 - acc: 0.0000e+00 - val_loss: 2.1358 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "1204/1204 [==============================] - 2s - loss: 2.9489 - acc: 0.0000e+00 - val_loss: 2.0918 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200074510f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=500,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 2.69 MSE (1.64 RMSE)\n",
      "Test Score: 3.20 MSE (1.79 RMSE)\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.02997986  3.10060059  6.18230042]\n",
      " [ 2.97312317  3.0433432   6.0698999 ]\n",
      " [ 3.01391388  3.01716705  5.95349976]\n",
      " [ 2.98368378  3.02642639  6.02549988]\n",
      " [ 2.96541534  3.01326324  5.94940002]\n",
      " [ 2.99049042  3.00425415  5.97619995]\n",
      " [ 2.69829834  2.71271271  5.28940002]\n",
      " [ 2.68768768  2.72272278  5.3826001 ]\n",
      " [ 2.6434433   2.6997998   5.3401001 ]\n",
      " [ 2.6435434   2.6825827   5.27280029]\n",
      " [ 2.6674173   2.69094086  5.3198999 ]\n",
      " [ 2.70770782  2.75615601  5.46600037]\n",
      " [ 2.67017029  2.69524536  5.35359985]\n",
      " [ 2.62912903  2.67967957  5.32440002]\n",
      " [ 2.53623627  2.60850861  5.21030029]\n",
      " [ 2.51246246  2.53588593  5.06380035]\n",
      " [ 2.48518524  2.50375381  4.97570007]\n",
      " [ 2.42252258  2.48353348  4.93649994]\n",
      " [ 2.37237244  2.44444443  4.82800018]\n",
      " [ 2.40580582  2.40615616  4.74880005]\n",
      " [ 2.41306305  2.41671677  4.80220032]\n",
      " [ 2.45970978  2.46421417  4.8701001 ]]\n",
      "0 5.85519958 7.46097 -0.215223185321 1.60577463646\n",
      "1 5.85990051 7.46097 -0.214593116128 1.60107370646\n",
      "2 6.39570007 7.46097 -0.142779497094 1.06527414646\n",
      "3 6.32909973 7.46097 -0.151705990883 1.13187448646\n",
      "4 6.28580017 7.46097 -0.157509463559 1.17517404646\n",
      "5 6.2498999 7.46097 -0.162321203817 1.21107431646\n",
      "6 6.29640015 7.46097 -0.156088740247 1.16457406646\n",
      "7 6.25960022 7.46097 -0.161021062613 1.20137399646\n",
      "8 6.23140015 7.46097 -0.164800739258 1.22957406646\n",
      "9 6.22460022 7.46097 -0.165712139004 1.23637399646\n",
      "10 6.5002002 7.46097 -0.128773265875 0.960774016461\n",
      "11 6.5901001 7.46097 -0.116723914491 0.870874116461\n",
      "12 6.68280029 7.46097 -0.104299238127 0.778173926461\n",
      "13 6.65409973 7.46097 -0.108145995825 0.806874486461\n",
      "14 6.45900024 7.46097 -0.134295327579 1.00197397646\n",
      "15 6.42400024 7.46097 -0.13898640397 1.03697397646\n",
      "16 6.39700012 7.46097 -0.142605250413 1.06397409646\n",
      "17 6.4025 7.46097 -0.141868097349 1.05847421646\n",
      "18 6.33140015 7.46097 -0.151397663856 1.12957406646\n",
      "19 6.29700012 7.46097 -0.156008325815 1.16397409646\n",
      "20 6.25820007 7.46097 -0.161208725773 1.20277414646\n",
      "21 6.30369995 7.46097 -0.155110342549 1.15727426646\n",
      "22 6.21830017 7.46097 -0.166556539456 1.24267404646\n",
      "23 6.25960022 7.46097 -0.161021062613 1.20137399646\n",
      "24 6.19539978 7.46097 -0.169625895995 1.26557443646\n",
      "25 6.18070007 7.46097 -0.17159610921 1.28027414646\n",
      "26 6.25630066 7.46097 -0.161463305128 1.20467355646\n",
      "27 6.25389954 7.46097 -0.161785129052 1.20707467646\n",
      "28 6.27419983 7.46097 -0.159064265876 1.18677438646\n",
      "29 6.16050049 7.46097 -0.174303474148 1.30047372646\n",
      "30 6.23390015 7.46097 -0.164465662373 1.22707406646\n",
      "31 6.2377002 7.46097 -0.163956338807 1.22327401646\n",
      "32 6.25650024 7.46097 -0.16143655527 1.20447397646\n",
      "33 6.20359985 7.46097 -0.16852683443 1.25737436646\n",
      "34 6.1377002 7.46097 -0.177359414209 1.32327401646\n",
      "35 5.99390015 7.46097 -0.19663304334 1.46707406646\n",
      "36 5.82929993 7.46097 -0.218694534939 1.63167428646\n",
      "37 5.88190063 7.46097 -0.211644423456 1.57907358646\n",
      "38 5.63 7.46097 -0.245406854834 1.83097421646\n",
      "39 5.70109985 7.46097 -0.235877288328 1.75987436646\n",
      "40 5.8 7.46097 -0.22262162665 1.66097421646\n",
      "41 5.80940002 7.46097 -0.221361734881 1.65157419646\n",
      "42 5.94880005 7.46097 -0.202677843749 1.51217416646\n",
      "43 6.00870056 7.46097 -0.194649333227 1.45227365646\n",
      "44 6.11470032 7.46097 -0.180442105468 1.34627389646\n",
      "45 6.16559998 7.46097 -0.173619985659 1.29537423646\n",
      "46 6.13 7.46097 -0.178391477821 1.33097421646\n",
      "47 6.08350037 7.46097 -0.184623858292 1.37747384646\n",
      "48 5.95080017 7.46097 -0.202409766158 1.51017404646\n",
      "49 6.00950012 7.46097 -0.194542167598 1.45147409646\n",
      "50 6.12340027 7.46097 -0.17927604461 1.33757394646\n",
      "51 6.08330017 7.46097 -0.184650691249 1.37767404646\n",
      "52 5.96140015 7.46097 -0.200989042845 1.49957406646\n",
      "53 5.975 7.46097 -0.199166244695 1.48597421646\n",
      "54 5.84820007 7.46097 -0.216161334924 1.61277414646\n",
      "55 5.78650024 7.46097 -0.224431009662 1.67447397646\n",
      "56 5.92640015 7.46097 -0.205680119236 1.53457406646\n",
      "57 6.00140015 7.46097 -0.195627812684 1.45957406646\n",
      "58 5.98670044 7.46097 -0.1975980259 1.47427377646\n",
      "59 5.86309998 7.46097 -0.214164288751 1.59787423646\n",
      "60 5.83159973 7.46097 -0.218386291011 1.62937448646\n",
      "61 5.96420044 7.46097 -0.200613717865 1.49677377646\n",
      "62 5.9048999 7.46097 -0.208561813956 1.55607431646\n",
      "63 5.83670044 7.46097 -0.217702639004 1.62427377646\n",
      "64 5.80700012 7.46097 -0.221683395288 1.65397409646\n",
      "65 5.9051001 7.46097 -0.208534980999 1.55587411646\n",
      "66 5.82409973 7.46097 -0.219391521666 1.63687448646\n",
      "67 5.91679993 7.46097 -0.206966843962 1.54417428646\n",
      "68 5.5898999 7.46097 -0.250781501474 1.87107431646\n",
      "69 5.485 7.46097 -0.264841314168 1.97597421646\n",
      "70 5.43179993 7.46097 -0.271971759664 2.02917428646\n",
      "71 5.37169983 7.46097 -0.280027021384 2.08927438646\n",
      "72 5.15119995 7.46097 -0.309580786563 2.30977426646\n",
      "73 5.14710022 7.46097 -0.310130276467 2.31387399646\n",
      "74 5.04700012 7.46097 -0.323546768348 2.41397409646\n",
      "75 5.01899994 7.46097 -0.327299653586 2.44197427646\n",
      "76 4.9552002 7.46097 -0.335850780845 2.50577401646\n",
      "77 5.15039978 7.46097 -0.309688033952 2.31057443646\n",
      "78 5.275 7.46097 -0.292987772513 2.18597421646\n",
      "79 5.28840027 7.46097 -0.291191724221 2.17257394646\n",
      "80 5.39340027 7.46097 -0.277118495048 2.06757394646\n",
      "81 5.31890015 7.46097 -0.287103802307 2.14207406646\n",
      "82 5.2551001 7.46097 -0.295654971115 2.20587411646\n",
      "83 5.20659973 7.46097 -0.302155512277 2.25437448646\n",
      "84 5.39200012 7.46097 -0.277306158209 2.06897409646\n",
      "85 5.46630005 7.46097 -0.267347682567 1.99467416646\n",
      "86 5.46670044 7.46097 -0.267294017993 1.99427377646\n",
      "87 5.46679993 7.46097 -0.267280683273 1.99417428646\n",
      "88 5.42559998 7.46097 -0.272802743638 2.03537423646\n",
      "89 5.32070007 7.46097 -0.286862557672 2.14027414646\n",
      "90 5.2952002 7.46097 -0.290280324476 2.16577401646\n",
      "91 5.30119995 7.46097 -0.28947617346 2.15977426646\n",
      "92 5.24849976 7.46097 -0.296539619663 2.21247445646\n",
      "93 5.34960022 7.46097 -0.282989048776 2.11137399646\n",
      "94 5.34030029 7.46097 -0.284235525407 2.12067392646\n",
      "95 5.22179993 7.46097 -0.30011821801 2.23917428646\n",
      "96 5.24840027 7.46097 -0.296552954382 2.21257394646\n",
      "97 5.325 7.46097 -0.286286234812 2.13597421646\n",
      "98 5.40960022 7.46097 -0.274947203535 2.05137399646\n",
      "99 5.40699951 7.46097 -0.275295778657 2.05397470646\n",
      "100 5.39080017 7.46097 -0.277466988412 2.07017404646\n",
      "101 5.26859985 7.46097 -0.293845589444 2.19237436646\n",
      "102 5.20039978 7.46097 -0.302986496251 2.26057443646\n",
      "103 5.23290039 7.46097 -0.298630414986 2.22807382646\n",
      "104 5.18820007 7.46097 -0.304621632581 2.27277414646\n",
      "105 4.98170013 7.46097 -0.332298975245 2.47927408646\n",
      "106 4.90920013 7.46097 -0.342016204912 2.55177408646\n",
      "107 5.04880005 7.46097 -0.323305522373 2.41217416646\n",
      "108 5.33149963 7.46097 -0.285415084502 2.12947458646\n",
      "109 5.39 7.46097 -0.2775742358 2.07097421646\n",
      "110 5.5722998 7.46097 -0.253140456148 1.88867441646\n",
      "111 5.6377002 7.46097 -0.244374791222 1.82327401646\n",
      "112 5.62130005 7.46097 -0.246572915693 1.83967416646\n",
      "113 5.4901001 7.46097 -0.264157743919 1.97087411646\n",
      "114 5.73410034 7.46097 -0.23145420777 1.72687387646\n",
      "115 5.4602002 7.46097 -0.268165250062 2.00077401646\n",
      "116 5.79040039 7.46097 -0.223908269617 1.67057382646\n",
      "117 5.7752002 7.46097 -0.225945562544 1.68577401646\n",
      "118 6.01170044 7.46097 -0.194247257049 1.44927377646\n",
      "119 5.92400024 7.46097 -0.206001780983 1.53697397646\n",
      "120 6.0677002 7.46097 -0.186741566991 1.39327401646\n",
      "121 6.03690002 7.46097 -0.190869738341 1.42407419646\n",
      "122 6.10940002 7.46097 -0.181152508674 1.35157419646\n",
      "123 6.07219971 7.46097 -0.186138494273 1.38877450646\n",
      "124 6.2252002 7.46097 -0.165631723232 1.23577401646\n",
      "125 6.18980042 7.46097 -0.170376382438 1.27117379646\n",
      "126 6.18230042 7.46097 -0.171381613093 1.27867379646\n",
      "127 6.0698999 7.46097 -0.186446739541 1.39107431646\n",
      "128 5.95349976 7.46097 -0.202047938074 1.50747445646\n",
      "129 6.02549988 7.46097 -0.192397707701 1.43547433646\n",
      "130 5.94940002 7.46097 -0.202597429318 1.51157419646\n",
      "131 5.97619995 7.46097 -0.199005414492 1.48477426646\n",
      "132 5.28940002 7.46097 -0.291057726975 2.17157419646\n",
      "133 5.3826001 7.46097 -0.278566049977 2.07837411646\n",
      "134 5.3401001 7.46097 -0.284262357023 2.12087411646\n",
      "135 5.27280029 7.46097 -0.293282601303 2.18817392646\n",
      "136 5.3198999 7.46097 -0.286969805061 2.14107431646\n",
      "137 5.46600037 7.46097 -0.267387848903 1.99497384646\n",
      "138 5.35359985 7.46097 -0.282452975352 2.10737436646\n",
      "139 5.32440002 7.46097 -0.286366650584 2.13657419646\n",
      "140 5.21030029 7.46097 -0.30165952343 2.25067392646\n",
      "141 5.06380035 7.46097 -0.321295020853 2.39717386646\n",
      "142 4.97570007 7.46097 -0.333103167811 2.48527414646\n",
      "143 4.93649994 7.46097 -0.338357190793 2.52447427646\n",
      "144 4.82800018 7.46097 -0.352899495437 2.63297403646\n",
      "145 4.74880005 7.46097 -0.36351474858 2.71217416646\n",
      "146 4.80220032 7.46097 -0.356357470127 2.65877389646\n",
      "147 4.8701001 7.46097 -0.347256811415 2.59087411646\n",
      "148 4.93 7.46097 -0.339228382652 2.53097421646\n"
     ]
    }
   ],
   "source": [
    "print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200085e7470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(p,color='red', label='prediction')\n",
    "plt.plot(y_test,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
