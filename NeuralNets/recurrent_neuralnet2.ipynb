{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*UkI9za9zTR-HL8uM15Wmzw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\n",
    "num_epochs = 100  # Batches are inside epochs\n",
    "total_series_length = 50000  \n",
    "truncated_backprop_length = 15  # \n",
    "state_size = 4  # No. of neurons in hidden layer ( 3 layer neural net)\n",
    "num_classes = 2  # No. of classes ( 0 and 1 )\n",
    "echo_step = 3  # \n",
    "batch_size = 5  # Inside epoch\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length  # No. of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 0, 0, ..., 1, 0, 1],\n",
      "       [1, 1, 0, ..., 1, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 0, 1],\n",
      "       [0, 0, 0, ..., 0, 1, 1]], dtype=int64), array([[0, 0, 0, ..., 0, 0, 1],\n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 1, ..., 0, 1, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 0],\n",
      "       [1, 0, 1, ..., 0, 1, 0]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Step 1 Collect data\n",
    "def generateData():\n",
    "    # 0,1 50k samples\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    # Shift 3 steps to left\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "    x = x.reshape((batch_size, -1)) \n",
    "    y = y.reshape((batch_size, -1))\n",
    "    \n",
    "    return (x, y)\n",
    "\n",
    "data = generateData()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*aFtwuFsboLV8z5PkEzNLXA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Schematic of the reshaped data-matrix, arrow curves shows adjacent time-steps that ended up on different rows. \n",
    "#Light-gray rectangle represent a “zero” and dark-gray a “one”.\n",
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*aFtwuFsboLV8z5PkEzNLXA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow works by first building up a computational graph, that \n",
    "#specifies what operations will be done. The input and output of this graph\n",
    "#is typically multidimensional arrays, also known as tensors. \n",
    "#The graph, or parts of it can then be executed iteratively in a \n",
    "#session, this can either be done on the CPU, GPU or even a resource \n",
    "#on a remote server.\n",
    "\n",
    "#operations and tensors\n",
    "\n",
    "#The two basic TensorFlow data-structures that will be used in this \n",
    "#example are placeholders and variables. On each run the batch data \n",
    "#is fed to the placeholders, which are “starting nodes” of the \n",
    "#computational graph. Also the RNN-state is supplied in a placeholder, \n",
    "#which is saved from the output of the previous run.\n",
    "\n",
    "#Step 2 - Build the Model\n",
    "\n",
    "#datatype, shape (5, 15) 2D array or matrix, batch size shape for later\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "#and one for the RNN state, 5,4 \n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The weights and biases of the network are declared as TensorFlow variables,\n",
    "#which makes them persistent across runs and enables them to be updated\n",
    "#incrementally for each batch.\n",
    "\n",
    "#3 layer recurrent net, one hidden state\n",
    "\n",
    "#randomly initialize weights\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "#anchor, improves convergance, matrix of 0s \n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*n45uYnAfTDrBvG87J-poCA.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now it’s time to build the part of the graph that resembles the actual RNN computation, \n",
    "#first we want to split the batch data into adjacent time-steps.\n",
    "\n",
    "# Unpack columns\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#so a bunch of arrays, 1 batch per time step\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*f2iL4zOkBUBGOpVE7kyajg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*f2iL4zOkBUBGOpVE7kyajg.png\")\n",
    "#Schematic of the current batch split into columns, the order index is shown on each data-point \n",
    "#and arrows show adjacent time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "#state placeholder\n",
    "current_state = init_state\n",
    "#series of states through time\n",
    "states_series = []\n",
    "\n",
    "\n",
    "#for each set of inputs\n",
    "#forward pass through the network to get new state value\n",
    "#store all states in memory\n",
    "for current_input in inputs_series:\n",
    "    #format input\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "    #mix both state and input data \n",
    "    input_and_state_concatenated = tf.concat(axis=1, values=[current_input, current_state])  # Increasing number of columns\n",
    "    #perform matrix multiplication between weights and input, add bias\n",
    "    #squash with a nonlinearity, for probabiolity value\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "    #store the state in memory\n",
    "    states_series.append(next_state)\n",
    "    #set current state to next one\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*fdwNNJ5UOE3Sx0R_Cyfmyg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "#second part of forward pass\n",
    "#logits short for logistic transform\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "#apply softmax nonlinearity for output probability\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "#measure loss, calculate softmax again on logits, then compute cross entropy\n",
    "#measures the difference between two probability distributions\n",
    "#this will return A Tensor of the same shape as labels and of the same type as logits \n",
    "#with the softmax cross entropy loss.\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "#computes average, one value\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "#use adagrad to minimize with .3 learning rate\n",
    "#minimize it with adagrad, not SGD\n",
    "#One downside of SGD is that it is sensitive to\n",
    "#the learning rate hyper-parameter. When the data are sparse and features have\n",
    "#different frequencies, a single learning rate for every weight update can have\n",
    "#exponential regret.\n",
    "#Some features can be extremely useful and informative to an optimization problem but \n",
    "#they may not show up in most of the training instances or data. If, when they do show up, \n",
    "#they are weighted equally in terms of learning rate as a feature that has shown up hundreds \n",
    "#of times we are practically saying that the influence of such features means nothing in the \n",
    "#overall optimization. it's impact per step in the stochastic gradient descent will be so small \n",
    "#that it can practically be discounted). To counter this, AdaGrad makes it such that features \n",
    "#that are more sparse in the data have a higher learning rate which translates into a larger \n",
    "#update for that feature\n",
    "#sparse features can be very useful.\n",
    "#Each feature has a different learning rate which is adaptable. \n",
    "#gives voice to the little guy who matters a lot\n",
    "#weights that receive high gradients will have their effective learning rate reduced, \n",
    "#while weights that receive small or infrequent updates will have their effective learning rate increased. \n",
    "#great paper http://seed.ucsd.edu/mediawiki/images/6/6a/Adagrad.pdf\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualizer\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-ae0feeafb530>:5: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a47da52b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.708804\n",
      "Step 100 Loss 0.700659\n",
      "Step 200 Loss 0.69147\n",
      "Step 300 Loss 0.688803\n",
      "Step 400 Loss 0.692897\n",
      "Step 500 Loss 0.684777\n",
      "Step 600 Loss 0.572007\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.421411\n",
      "Step 100 Loss 0.0407428\n",
      "Step 200 Loss 0.0169775\n",
      "Step 300 Loss 0.0112504\n",
      "Step 400 Loss 0.00808688\n",
      "Step 500 Loss 0.00836783\n",
      "Step 600 Loss 0.00584262\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.397992\n",
      "Step 100 Loss 0.00514043\n",
      "Step 200 Loss 0.00390044\n",
      "Step 300 Loss 0.00317126\n",
      "Step 400 Loss 0.004362\n",
      "Step 500 Loss 0.00361888\n",
      "Step 600 Loss 0.00268734\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.24638\n",
      "Step 100 Loss 0.00261539\n",
      "Step 200 Loss 0.00223732\n",
      "Step 300 Loss 0.00199044\n",
      "Step 400 Loss 0.00184866\n",
      "Step 500 Loss 0.00187744\n",
      "Step 600 Loss 0.00185572\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.158465\n",
      "Step 100 Loss 0.00143004\n",
      "Step 200 Loss 0.001459\n",
      "Step 300 Loss 0.00175557\n",
      "Step 400 Loss 0.00139214\n",
      "Step 500 Loss 0.00142209\n",
      "Step 600 Loss 0.00138144\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.314336\n",
      "Step 100 Loss 0.000978642\n",
      "Step 200 Loss 0.00168524\n",
      "Step 300 Loss 0.00161036\n",
      "Step 400 Loss 0.00103349\n",
      "Step 500 Loss 0.000796786\n",
      "Step 600 Loss 0.00129306\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.26375\n",
      "Step 100 Loss 0.00123015\n",
      "Step 200 Loss 0.00103738\n",
      "Step 300 Loss 0.000890996\n",
      "Step 400 Loss 0.000907819\n",
      "Step 500 Loss 0.000811958\n",
      "Step 600 Loss 0.000741505\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.25978\n",
      "Step 100 Loss 0.00118629\n",
      "Step 200 Loss 0.000962587\n",
      "Step 300 Loss 0.000629519\n",
      "Step 400 Loss 0.00105772\n",
      "Step 500 Loss 0.000802881\n",
      "Step 600 Loss 0.000725098\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.20915\n",
      "Step 100 Loss 0.000818589\n",
      "Step 200 Loss 0.000671475\n",
      "Step 300 Loss 0.000730428\n",
      "Step 400 Loss 0.000742192\n",
      "Step 500 Loss 0.000718399\n",
      "Step 600 Loss 0.000997092\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.245838\n",
      "Step 100 Loss 0.000757328\n",
      "Step 200 Loss 0.000639918\n",
      "Step 300 Loss 0.000600907\n",
      "Step 400 Loss 0.000638964\n",
      "Step 500 Loss 0.000648192\n",
      "Step 600 Loss 0.000460978\n",
      "New data, epoch 10\n",
      "Step 0 Loss 0.198134\n",
      "Step 100 Loss 0.000710784\n",
      "Step 200 Loss 0.000500848\n",
      "Step 300 Loss 0.00053639\n",
      "Step 400 Loss 0.000610752\n",
      "Step 500 Loss 0.000446566\n",
      "Step 600 Loss 0.000475104\n",
      "New data, epoch 11\n",
      "Step 0 Loss 0.211481\n",
      "Step 100 Loss 0.000707922\n",
      "Step 200 Loss 0.000456363\n",
      "Step 300 Loss 0.000597018\n",
      "Step 400 Loss 0.000443111\n",
      "Step 500 Loss 0.000404989\n",
      "Step 600 Loss 0.000514805\n",
      "New data, epoch 12\n",
      "Step 0 Loss 0.314189\n",
      "Step 100 Loss 0.000446624\n",
      "Step 200 Loss 0.000406388\n",
      "Step 300 Loss 0.000520657\n",
      "Step 400 Loss 0.000393874\n",
      "Step 500 Loss 0.000448876\n",
      "Step 600 Loss 0.000396909\n",
      "New data, epoch 13\n",
      "Step 0 Loss 0.207352\n",
      "Step 100 Loss 0.000468924\n",
      "Step 200 Loss 0.000475304\n",
      "Step 300 Loss 0.000489698\n",
      "Step 400 Loss 0.000318956\n",
      "Step 500 Loss 0.000379732\n",
      "Step 600 Loss 0.000362642\n",
      "New data, epoch 14\n",
      "Step 0 Loss 0.245657\n",
      "Step 100 Loss 0.00077372\n",
      "Step 200 Loss 0.000464736\n",
      "Step 300 Loss 0.000398161\n",
      "Step 400 Loss 0.000336463\n",
      "Step 500 Loss 0.000363535\n",
      "Step 600 Loss 0.000449752\n",
      "New data, epoch 15\n",
      "Step 0 Loss 0.364056\n",
      "Step 100 Loss 0.0019136\n",
      "Step 200 Loss 0.00149476\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ae0feeafb530>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Step\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_predictions_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-aaf79cd4affa>\u001b[0m in \u001b[0;36mplot\u001b[1;34m(loss_list, predictions_series, batchX, batchY)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mleft_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncated_backprop_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_series_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_series_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingle_output_series\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(left, height, width, bottom, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   2702\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2703\u001b[0m         ret = ax.bar(left, height, width=width, bottom=bottom, data=data,\n\u001b[1;32m-> 2704\u001b[1;33m                      **kwargs)\n\u001b[0m\u001b[0;32m   2705\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2706\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1898\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, left, height, width, bottom, **kwargs)\u001b[0m\n\u001b[0;32m   2118\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_nolegend_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m                 )\n\u001b[0;32m   2122\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \"\"\"\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[0mPatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;31m# unscaled dashes.  Needed to scale dash patterns by lw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_us_dashes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mset_facecolor\u001b[1;34m(self, color)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_facecolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_facecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m_set_facecolor\u001b[1;34m(self, color)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch.facecolor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_facecolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shreyansh singh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# tuple color.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_cast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m# Test the dtype explicitly as `map(float, ...)`, `np.array(...,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neRE3kJrBDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a47f408e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 3 Training the network\n",
    "with tf.Session() as sess:\n",
    "    #we stupidly have to do this everytime, it should just know\n",
    "    #that we initialized these vars. v2 guys, v2..\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #interactive mode\n",
    "    plt.ion()\n",
    "    #initialize the figure\n",
    "    plt.figure()\n",
    "    #show the graph\n",
    "    plt.show()\n",
    "    #to show the loss decrease\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        #generate data at eveery epoch, batches run in epochs\n",
    "        x,y = generateData()\n",
    "        #initialize an empty hidden state\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        #each batch\n",
    "        for batch_idx in range(num_batches):\n",
    "            #starting and ending point per batch\n",
    "            #since weights reoccuer at every layer through time\n",
    "            #These layers will not be unrolled to the beginning of time, \n",
    "            #that would be too computationally expensive, and are therefore truncated \n",
    "            #at a limited number of time-steps\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "            \n",
    "            #run the computation graph, give it the values\n",
    "            #we calculated earlier\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*uKuUKp_m55zAPCzaIemucA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*uKuUKp_m55zAPCzaIemucA.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ytquMdmGMJo0-3kxMCi1Gg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*ytquMdmGMJo0-3kxMCi1Gg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
